<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>深度学习之图像分类（二）-- pytorch查看中间层特征矩阵以及卷积核参数</title>
    <link href="/2024/03/28/pytorch%E6%9F%A5%E7%9C%8B%E4%B8%AD%E9%97%B4%E5%B1%82%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E4%BB%A5%E5%8F%8A%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%8F%82%E6%95%B0/"/>
    <url>/2024/03/28/pytorch%E6%9F%A5%E7%9C%8B%E4%B8%AD%E9%97%B4%E5%B1%82%E7%89%B9%E5%BE%81%E7%9F%A9%E9%98%B5%E4%BB%A5%E5%8F%8A%E5%8D%B7%E7%A7%AF%E6%A0%B8%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h2 id="深度学习之图像分类（二）pytorch查看中间层特征矩阵以及卷积核参数"><a href="#深度学习之图像分类（二）pytorch查看中间层特征矩阵以及卷积核参数" class="headerlink" title="深度学习之图像分类（二）pytorch查看中间层特征矩阵以及卷积核参数"></a>深度学习之图像分类（二）pytorch查看中间层特征矩阵以及卷积核参数</h2><p>在开始学习深度学习图像分类模型Backbone理论知识之前，先看看如何在 pytorch 框架中查看中间层特征矩阵以及卷积核参数，学习视频源于 <a href="https://www.bilibili.com/video/BV1z7411f7za">Bilibili</a>。</p><p>耳听为虚，眼见为实！可视化 feature maps 以及 kernel weights 在论文展示中非常重要，同时对于个人分析神经网络学习的特性也至关重要。本文学习的完整代码详见 <a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/analyze_weights_featuremap">此处</a>。</p><h3 id="1-可视化-feature-maps"><a href="#1-可视化-feature-maps" class="headerlink" title="1. 可视化 feature maps"></a>1. 可视化 feature maps</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> alexnet_model <span class="hljs-keyword">import</span> AlexNet<br><span class="hljs-keyword">from</span> resnet_model <span class="hljs-keyword">import</span> resnet34<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms<br><br><span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">class AlexNet(nn.Module):</span><br><span class="hljs-string">...</span><br><span class="hljs-string"></span><br><span class="hljs-string">def forward(self, x):</span><br><span class="hljs-string"># 存储网络中间结果</span><br><span class="hljs-string">        outputs = []</span><br><span class="hljs-string">        for name, module in self.features.named_children():</span><br><span class="hljs-string">            x = module(x)</span><br><span class="hljs-string">            if name in [&quot;0&quot;, &quot;3&quot;, &quot;6&quot;]:</span><br><span class="hljs-string">                outputs.append(x)</span><br><span class="hljs-string"></span><br><span class="hljs-string"># 网络正向传播过程返回的是中间结果</span><br><span class="hljs-string">        return outputs</span><br><span class="hljs-string">&quot;&quot;&quot;</span><br><br><span class="hljs-comment"># 与训练过程保持一致</span><br>data_transform = transforms.Compose(<br>    [transforms.Resize((<span class="hljs-number">224</span>, <span class="hljs-number">224</span>)),<br>     transforms.ToTensor(),<br>     transforms.Normalize((<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>), (<span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>, <span class="hljs-number">0.5</span>))])<br><br><span class="hljs-comment"># data_transform = transforms.Compose(</span><br><span class="hljs-comment">#     [transforms.Resize(256),</span><br><span class="hljs-comment">#      transforms.CenterCrop(224),</span><br><span class="hljs-comment">#      transforms.ToTensor(),</span><br><span class="hljs-comment">#      transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])</span><br><br><span class="hljs-comment"># create model</span><br>model = AlexNet(num_classes=<span class="hljs-number">5</span>)<br><span class="hljs-comment"># model = resnet34(num_classes=5)</span><br><span class="hljs-comment"># load model weights</span><br>model_weight_path = <span class="hljs-string">&quot;./AlexNet.pth&quot;</span>  <span class="hljs-comment"># &quot;./resNet34.pth&quot;</span><br>model.load_state_dict(torch.load(model_weight_path))<br><span class="hljs-built_in">print</span>(model)<br><br><span class="hljs-comment"># load image</span><br>img = Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;../tulip.jpg&quot;</span>)<br><span class="hljs-comment"># [N, C, H, W]</span><br>img = data_transform(img)<br><span class="hljs-comment"># expand batch dimension</span><br>img = torch.unsqueeze(img, dim=<span class="hljs-number">0</span>)<span class="hljs-comment"># 增加一个 batch 维度</span><br><br><span class="hljs-comment"># forward</span><br>out_put = model(img)<br><span class="hljs-keyword">for</span> feature_map <span class="hljs-keyword">in</span> out_put:<span class="hljs-comment"># 使用 AlexNet 的话，out_put 是一个 list，有三个元素</span><br>    <span class="hljs-comment"># [N, C, H, W] -&gt; [C, H, W]</span><br>    im = np.squeeze(feature_map.detach().numpy())<span class="hljs-comment"># 只输入了一张图，squeeze 压缩掉 batch 维度，detach() 去除梯度信息</span><br>    <span class="hljs-comment"># [C, H, W] -&gt; [H, W, C]</span><br>    im = np.transpose(im, [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">0</span>])<br><br>    <span class="hljs-comment"># show top 12 feature maps</span><br>    plt.figure()<br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">12</span>):<br>        ax = plt.subplot(<span class="hljs-number">3</span>, <span class="hljs-number">4</span>, i+<span class="hljs-number">1</span>)<br>        <span class="hljs-comment"># [H, W, C]</span><br>        <span class="hljs-comment"># 我们特征矩阵每一个 channel 所对应的是一个二维的特征矩阵，就像灰度图一样，channel = 1</span><br>        <span class="hljs-comment"># 如果不指定 cmap=&#x27;gray&#x27; 默认是以蓝色和绿色替换黑色和白色</span><br>        plt.imshow(im[:, :, i], cmap=<span class="hljs-string">&#x27;gray&#x27;</span>)<br>    plt.show()<br><br></code></pre></td></tr></table></figure><p>以 AlexNet 为例，下图展示了测试的原始图片：</p><p><img src="/images/classify/base/featuremap-0.png" alt="img0"></p><p>下图打印了第一个卷积层计算得到的前 12 个通道的特征图，每个特征图的切片中可以通过明暗程度来理解卷积层 1 所关注的信息，其中越亮的地方就是卷积核越感兴趣的地方。通过对比原图发现，由于这是卷积层 1 输出的特征矩阵，所以基本还是能看出一些原始图的信息。</p><p><img src="/images/classify/base/featuremap-1.png" alt="img1"></p><p>卷积层 2 输出的信息如下所示，由于越往后，抽象程度越高，所以越来越不像所看到的花了。另外有些卷积核没有起到什么作用的，卷积之后得到的特征矩阵都是黑色的，说明根本就没有学到什么有用的信息。</p><p><img src="/images/classify/base/featuremap-2.png" alt="img2"></p><p>如果之前不增加 <code>cmap=&#39;gray&#39;</code> 的话，图片如下所示：</p><p><img src="/images/classify/base/featuremap-3.png" alt="img3"></p><p>相比而言，使用 ResNet 得到的结果则更好，第一个卷积层输出结果可见它检测到了纹理信息，以及高亮部分展示了花朵等等。ResNet 的 layer 1 输出的特征图结果也比 AlexNet 很多全黑的要好。可能有两个原因造成这种情况，首先是 ResNet 本身比 AlexNet 要好；其次则是 ResNet 使用了迁移学习，用了 ImageNet 预训练的权重来训练的。</p><p><img src="/images/classify/base/featuremap-4.png" alt="img4"></p><p><img src="/images/classify/base/featuremap-5.png" alt="img5"></p><p><strong>哦豁，如果想看全连接层的输出特征矩阵怎么办呢？</strong></p><h3 id="2-可视化-kernel-weights"><a href="#2-可视化-kernel-weights" class="headerlink" title="2. 可视化 kernel weights"></a>2. 可视化 kernel weights</h3><p>同样以 AlexNet 和 ResNet 为例。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> alexnet_model <span class="hljs-keyword">import</span> AlexNet<br><span class="hljs-keyword">from</span> resnet_model <span class="hljs-keyword">import</span> resnet34<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><br><span class="hljs-comment"># create model</span><br>model = AlexNet(num_classes=<span class="hljs-number">5</span>)<br><span class="hljs-comment"># model = resnet34(num_classes=5)</span><br><span class="hljs-comment"># load model weights</span><br>model_weight_path = <span class="hljs-string">&quot;./AlexNet.pth&quot;</span>  <span class="hljs-comment"># &quot;resNet34.pth&quot;</span><br>model.load_state_dict(torch.load(model_weight_path))<br><span class="hljs-built_in">print</span>(model)<br><br><span class="hljs-comment"># model.state_dict() 获取模型所有的可训练参数的字典；.keys() 获取名称</span><br>weights_keys = model.state_dict().keys()<br><span class="hljs-keyword">for</span> key <span class="hljs-keyword">in</span> weights_keys:<br>    <span class="hljs-comment"># remove num_batches_tracked para(in bn)</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-string">&quot;num_batches_tracked&quot;</span> <span class="hljs-keyword">in</span> key:<br>        <span class="hljs-keyword">continue</span><br>  <br>    <span class="hljs-comment"># [kernel_number, kernel_channel, kernel_height, kernel_width]</span><br>    <span class="hljs-comment"># 输出深度，输入深度，卷积核高，卷积核宽</span><br>    weight_t = model.state_dict()[key].numpy()<br><br>    <span class="hljs-comment"># read a kernel information</span><br>    <span class="hljs-comment"># k = weight_t[0, :, :, :]# 读取第一个卷积核</span><br><br>    <span class="hljs-comment"># calculate mean, std, min, max</span><br>    <span class="hljs-comment"># 计算均值，标准差，最大值和最小值。</span><br>    weight_mean = weight_t.mean()<br>    weight_std = weight_t.std(ddof=<span class="hljs-number">1</span>)<br>    weight_min = weight_t.<span class="hljs-built_in">min</span>()<br>    weight_max = weight_t.<span class="hljs-built_in">max</span>()<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;mean is &#123;&#125;, std is &#123;&#125;, min is &#123;&#125;, max is &#123;&#125;&quot;</span>.<span class="hljs-built_in">format</span>(weight_mean,<br>                                                               weight_std,<br>                                                               weight_max,<br>                                                               weight_min))<br><br>    <span class="hljs-comment"># plot hist image</span><br>    plt.close()<br>    weight_vec = np.reshape(weight_t, [-<span class="hljs-number">1</span>])<span class="hljs-comment"># 卷积核权重展成一维的向量 --- 原始卷积核太小了就3x3</span><br>    plt.hist(weight_vec, bins=<span class="hljs-number">50</span>)<span class="hljs-comment"># 统计卷积核权重值直方图的分布</span><br>    plt.title(key)<br>    plt.show()<br></code></pre></td></tr></table></figure><p>下图展示了卷积层 1 的权重以及 bias 的分布。</p><p><img src="/images/classify/base/kernel-1.png" alt="img6"></p><p><img src="/images/classify/base/kernel-2.png" alt="img7"></p><p>（有时候能看到，很多卷积核参数都是 0…）</p>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>图像分类</category>
      
      <category>基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>深度学习之图像分类（一）-- 分类模型的混淆矩阵</title>
    <link href="/2024/03/28/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/"/>
    <url>/2024/03/28/%E5%88%86%E7%B1%BB%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%B7%B7%E6%B7%86%E7%9F%A9%E9%98%B5/</url>
    
    <content type="html"><![CDATA[<h2 id="深度学习之图像分类（一）分类模型的混淆矩阵"><a href="#深度学习之图像分类（一）分类模型的混淆矩阵" class="headerlink" title="深度学习之图像分类（一）分类模型的混淆矩阵"></a>深度学习之图像分类（一）分类模型的混淆矩阵</h2><p>今天开始学习深度学习图像分类模型Backbone理论知识，首先学习分类模型的混淆矩阵，学习视频源于 <a href="https://www.bilibili.com/video/BV1GV411C7AW">Bilibili</a>。</p><p><img src="/images/classify/base/matrix-5.png" alt="img5"></p><h3 id="1-混淆矩阵"><a href="#1-混淆矩阵" class="headerlink" title="1. 混淆矩阵"></a>1. 混淆矩阵</h3><p>混淆矩阵是评判模型结果的一种指标，属于模型评估的一部分，常用语评判分类模型的优劣。图中左下角为混淆矩阵的一个示例，横坐标为 True Label，纵坐标为 Predicted Label。混淆矩阵每一行对应着预测属于该类的所有样本，混淆矩阵的对角线表示预测正确的样本个数。希望网络预测过程中，将预测类别分布在对角线上。预测值在对角线上分布越密集，则表现模型性能越好。通过混淆矩阵还容易看出模型对于哪些类别容易分类出错。</p><p>利用混淆矩阵可以算出精确率，召回率和特异度，这三个指标是对于每个类别得到的结果。注意到，精确率和准确率 Accuracy 是不一样的。准确率是使用所有预测正确样本的个数除以所有样本数量之和。</p><p><img src="/images/classify/base/matrix-0.png" alt="img0"></p><h4 id="1-1-二分类混淆矩阵"><a href="#1-1-二分类混淆矩阵" class="headerlink" title="1.1 二分类混淆矩阵"></a>1.1 二分类混淆矩阵</h4><p>我们首先以二分类混淆矩阵作为讲解。首先每一列表示真实值的标签，每一列表示预测值的标签。Positive 为正样本，Negative 为负样本。此时我们可以有四种分类：</p><ul><li>真实值为 Positive，预测值为 Positive，标记为 TP</li><li>真实值为 Positive，预测值为 Negative，标记为 FN    — 假阴性</li><li>真实值为 Negative，预测值为 Positive，标记为 FP     — 假阳性</li><li>真实值为 Negative，预测值为 Negative，标记为 TN</li></ul><p>TP 和 TN 都对应着网络预测正确的部分，FP 和 FN 对应着网络预测错误的部分。所以我们期望 TP 和 TN 越大越好，而 FP 和 FN 越小越好。</p><p><img src="/images/classify/base/matrix-1.png" alt="img1"></p><p>有了 TP、FN、FP、TN 的概念后，我们就可以引入准确率 (Acc, Accuracy)、精确率 (PPV, Positive Predictive Value)、召回率 (TPR, True Positive Rate) 以及特异度 (TNR, True Negative Rate)。注意到，准确率是对所有样本而言的，精确率召回率以及特异度是对于每个类别而言的。计算公式如下表所示：</p><ul><li>准确率 Acc: 模型正确分类样本数占总样本数的比例（所有类别）</li><li>精确率 PPV: 模型预测的所有 positive 中，预测正确的比例</li><li>召回率 TPR: 所有真实 positive 中，模型预测正确的 positive 比例</li><li>特异度 TNR: 所有真实 negative 中，模型预测正确的 negative 比例</li></ul><p><img src="/images/classify/base/matrix-2.png" alt="img2"></p><h4 id="1-2-混淆矩阵计算实例"><a href="#1-2-混淆矩阵计算实例" class="headerlink" title="1.2 混淆矩阵计算实例"></a>1.2 混淆矩阵计算实例</h4><p>下图给出了一个计算指标的实例，以猫狗猪三分类为例。准确率计算结果如下所示：</p><p><img src="/images/classify/base/matrix-3.png" alt="img3"></p><p>为了算针对 <code>猫</code> 类别的精确率召回率以及特异度，我们统一将狗和猪融合为不为猫的情况。精确率 Precision &#x3D; 10 &#x2F; (10 + 3) &#x3D; 0.77，同样的能算出召回率 Recall &#x3D; 10 &#x2F; (10 + 8) &#x3D; 0.56，特异度 Sepcificity &#x3D; 45 &#x2F; (45 + 3) &#x3D; 0.94。</p><p><img src="/images/classify/base/matrix-4.png" alt="img4"></p><h3 id="2-混淆矩阵代码"><a href="#2-混淆矩阵代码" class="headerlink" title="2. 混淆矩阵代码"></a>2. 混淆矩阵代码</h3><p>完整代码详见 <a href="https://github.com/WZMIAOMIAO/deep-learning-for-image-processing/tree/master/pytorch_classification/ConfusionMatrix">此处</a>。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> json<br><br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> transforms, datasets<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<span class="hljs-comment"># 用 numpy 实现，目的是 pytorch 和 tensorflow 的框架都能使用，label.numpy()</span><br><span class="hljs-keyword">from</span> tqdm <span class="hljs-keyword">import</span> tqdm<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> prettytable <span class="hljs-keyword">import</span> PrettyTable<br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">ConfusionMatrix</span>(<span class="hljs-title class_ inherited__">object</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;</span><br><span class="hljs-string">    注意，如果显示的图像不全，是matplotlib版本问题</span><br><span class="hljs-string">    本例程使用matplotlib-3.2.1(windows and ubuntu)绘制正常</span><br><span class="hljs-string">    需要额外安装prettytable库: pip install prettytable</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, num_classes: <span class="hljs-built_in">int</span>, labels: <span class="hljs-built_in">list</span></span>):<br>        self.matrix = np.zeros((num_classes, num_classes))<span class="hljs-comment"># 初始化混淆矩阵</span><br>        self.num_classes = num_classes<br>        self.labels = labels<br><br>    <span class="hljs-comment"># 混淆矩阵更新</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">update</span>(<span class="hljs-params">self, preds, labels</span>):<br>        <span class="hljs-keyword">for</span> p, t <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(preds, labels):<br>            self.matrix[p, t] += <span class="hljs-number">1</span><br><br>    <span class="hljs-comment"># 计算并打印评价指标</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">summary</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-comment"># calculate accuracy</span><br>        sum_TP = <span class="hljs-number">0</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_classes):<br>            sum_TP += self.matrix[i, i]<span class="hljs-comment"># 对角线元素求和</span><br>        acc = sum_TP / np.<span class="hljs-built_in">sum</span>(self.matrix)<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;the model accuracy is &quot;</span>, acc)<br><br>        <span class="hljs-comment"># precision, recall, specificity</span><br>        table = PrettyTable()<br>        table.field_names = [<span class="hljs-string">&quot;&quot;</span>, <span class="hljs-string">&quot;Precision&quot;</span>, <span class="hljs-string">&quot;Recall&quot;</span>, <span class="hljs-string">&quot;Specificity&quot;</span>]<span class="hljs-comment"># 第一个元素是类别标签</span><br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_classes):<span class="hljs-comment"># 针对每个类别进行计算</span><br>            <span class="hljs-comment"># 整合其他行列为不属于该类的情况</span><br>            TP = self.matrix[i, i]<br>            FP = np.<span class="hljs-built_in">sum</span>(self.matrix[i, :]) - TP<br>            FN = np.<span class="hljs-built_in">sum</span>(self.matrix[:, i]) - TP<br>            TN = np.<span class="hljs-built_in">sum</span>(self.matrix) - TP - FP - FN<br>            Precision = <span class="hljs-built_in">round</span>(TP / (TP + FP), <span class="hljs-number">3</span>) <span class="hljs-keyword">if</span> TP + FP != <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0.</span><span class="hljs-comment"># 注意分母为 0 的情况</span><br>            Recall = <span class="hljs-built_in">round</span>(TP / (TP + FN), <span class="hljs-number">3</span>) <span class="hljs-keyword">if</span> TP + FN != <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0.</span><br>            Specificity = <span class="hljs-built_in">round</span>(TN / (TN + FP), <span class="hljs-number">3</span>) <span class="hljs-keyword">if</span> TN + FP != <span class="hljs-number">0</span> <span class="hljs-keyword">else</span> <span class="hljs-number">0.</span><br>            table.add_row([self.labels[i], Precision, Recall, Specificity])<br>        <span class="hljs-built_in">print</span>(table)<br><br>    <span class="hljs-comment"># 可视化混淆矩阵</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">plot</span>(<span class="hljs-params">self</span>):<br>        matrix = self.matrix<br>        <span class="hljs-built_in">print</span>(matrix)<br>        plt.imshow(matrix, cmap=plt.cm.Blues)<span class="hljs-comment"># 从白色到蓝色</span><br><br>        <span class="hljs-comment"># 设置x轴坐标label</span><br>        plt.xticks(<span class="hljs-built_in">range</span>(self.num_classes), self.labels, rotation=<span class="hljs-number">45</span>)<span class="hljs-comment"># x 轴标签旋转 45 度方便展示</span><br>        <span class="hljs-comment"># 设置y轴坐标label</span><br>        plt.yticks(<span class="hljs-built_in">range</span>(self.num_classes), self.labels)<br>        <span class="hljs-comment"># 显示colorbar</span><br>        plt.colorbar()<br>        plt.xlabel(<span class="hljs-string">&#x27;True Labels&#x27;</span>)<br>        plt.ylabel(<span class="hljs-string">&#x27;Predicted Labels&#x27;</span>)<br>        plt.title(<span class="hljs-string">&#x27;Confusion matrix&#x27;</span>)<br><br>        <span class="hljs-comment"># 在图中标注数量/概率信息</span><br>        thresh = matrix.<span class="hljs-built_in">max</span>() / <span class="hljs-number">2</span><br>        <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_classes):<br>            <span class="hljs-keyword">for</span> y <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(self.num_classes):<br>                <span class="hljs-comment"># 注意这里的matrix[y, x]不是matrix[x, y]</span><br>                <span class="hljs-comment"># 画图的时候横坐标是x，纵坐标是y</span><br>                info = <span class="hljs-built_in">int</span>(matrix[y, x])<br>                plt.text(x, y, info,<br>                         verticalalignment=<span class="hljs-string">&#x27;center&#x27;</span>,<br>                         horizontalalignment=<span class="hljs-string">&#x27;center&#x27;</span>,<br>                         color=<span class="hljs-string">&quot;white&quot;</span> <span class="hljs-keyword">if</span> info &gt; thresh <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;black&quot;</span>)<br>        plt.tight_layout()<span class="hljs-comment"># 图形显示更加紧凑</span><br>        plt.show()<br><br></code></pre></td></tr></table></figure><h3 id="3-混淆矩阵用途"><a href="#3-混淆矩阵用途" class="headerlink" title="3. 混淆矩阵用途"></a>3. 混淆矩阵用途</h3><ul><li>混淆矩阵能够帮助我们迅速可视化各种类别误分为其它类别的比重，这样能够帮我们调整后续模型，比如一些类别设置权重衰减等</li><li>在一些论文的实验分析中，可以列出混淆矩阵，行和列均为 label 种类，可以通过该矩阵验证自己 model 预测复杂 label 的能力是否强于其他 model，只要自己 model 将复杂 label 误判为其它类别比其他 model 误判的少，就可以说明自己 model 预测复杂 label 的能力强于其他 model。</li></ul>]]></content>
    
    
    <categories>
      
      <category>深度学习</category>
      
      <category>图像分类</category>
      
      <category>基础知识</category>
      
    </categories>
    
    
    <tags>
      
      <tag>原创</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
